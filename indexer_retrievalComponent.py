'''
!!!
NO LONGER USED
!!!
'''
'''
For each link, parse it using soup and extract words
tokenize the extracted words

For each word from each link:
if in current Index, add document id to value of word key
if not, create new word key with document id as value

(modified Token, document ID)

After all documents parsed, sort by terms
Remove duplicates
Add frequency information

Dictionary File and postings file
Linked List to store document IDs

'''